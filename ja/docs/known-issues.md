# 既知の問題

| 日時 | カテゴリ | 内容 | 状況 |
|:--|:--|:--|:--|
| 2021/12/17 | Application | 計算ノード(A)上でpytorchとNCCLを使用する分散深層学習の実行に失敗する現象を確認しています。 | 2021/12/17<br>現在原因調査中 |
| 2021/10/19 | MPI | 計算ノード(V)上のOpenMPI 3.1.6において、mpirunコマンドに-mca pml cmフラグを指定した場合に、MPI_Send/MPI_Recvで処理が止まり先に進まない現象を確認しています。 | OpenMPI 3系はすでに非サポート状態のため、OpenMPI 4系を利用してください。|
| 2021/07/06 | Singularity | Remote Builderサービスの障害により、リモートビルド機能が利用できません。 | 2021/07/21<br>対応完了。Remote Builder サービス内で発生していたネットワークの問題が解消されました。 |
| 2021/05/26 | GPU | 繰り返しGPUを使う場合にステータスがDまたはZでプロセスが残り、GPUメモリが解放されない現象が確認されています。その後にそのGPUを利用すると、GPUメモリが解放されていないため後続のプロセスが正常に実行されません。本事象を確認したら<qa@abci.ai>までご連絡ください。 | 2021/07/12<br>現在、原因究明中 |
| 2021/05/17 | MPI | Open MPI 4.0.5にて、66ノード以上を使用したプログラム実行が異常終了することを確認しています。66ノード以上を使用する場合、MCAパラメータplm_rsh_no_tree_spawn trueおよびplm_rsh_num_concurrent $NHOSTSを指定してプログラムを実行してください。<BR><BR>$ mpirun -mca plm_rsh_no_tree_spawn true -mca plm_rsh_num_concurrent $NHOSTS ./a.out | 2021/05/31<br>対応完了。これらMCAパラメータのデフォルト値を変更しました。 |
| 2020/09/30 | Singularity | 以下のセキュリティ問題が報告されています。インタラクティブノードや、Full以外の資源タイプでSingularityPROを使用する時に影響を受けます。更新するまでは、SingularityPROはFull計算タイプでご利用ください。<BR><BR>[CVE-2020-25039](https://github.com/hpcng/singularity/security/advisories/GHSA-w6v2-qchm-grj7)<BR>[CVE-2020-25040](https://github.com/hpcng/singularity/security/advisories/GHSA-jv9c-w74q-6762) | 2020/10/09<br>対応完了。問題が修正されている 3.5-4 へアップデートしました。 |
| 2020/01/14 | Cloud Storage | 他グループに ACL で write許可設定したバケットにて、他グループがオブジェクトを作成・削除した場合、課金計算が正しく行われません。| 2020/04/03<br>対応完了。問題が修正されたバージョンにアップデートしました。 |
| 2019/11/14 | Cloud Storage | オブジェクトストレージの不具合により、マルチパートに分割して保存されたオブジェクトの上書き時または削除時に以下のエラーメッセージが出力されます。<BR>[上書き時] upload failed: object to s3://mybucket/object An error occurred (None) when calling the CompleteMultipartUpload operation: undefined<BR>[削除時] delete failed: s3://mybucket/object An error occurred (None) when calling the DeleteObject operation: undefined<BR><BR>AWS CLI の s3 コマンドを使用した場合、サイズの大きなファイルはマルチパート分割されます。サイズの大きなファイルを扱う場合、[こちら](https://docs.aws.amazon.com/cli/latest/topic/s3-config.html)を参照し multipart_threshold を大きな値に設定ください。 | 2019/12/17<br>対応完了。マルチパートアップロードでサイズの大きなファイルのアップロードが可能になりました。 |
| 2019/10/04 | MPI | MVPICH2-GDR 2.3.2のMPI_Allreduceにて、GPUメモリ間での通信を行った際、以下のノード数、GPU数、メッセージサイズの組み合わせでfloating point exceptionが発生することを確認しています。<BR>Nodes: 28, GPU/Node: 4, Message size: 256KB<BR>Nodes: 30, GPU/Node: 4, Message size: 256KB<BR>Nodes: 33, GPU/Node: 4, Message size: 256KB<BR>Nodes: 34, GPU/Node: 4, Message size: 256KB | 2020/04/21<br>対応完了。問題が修正されたバージョンにアップデートしました。 |
| 2019/04/10 | Job | ジョブスケジューラのアップデート(8.5.4 -> 8.6.3)に伴い、以下のジョブ投入オプションは引数が必須になりました。<BR>リソースタイプ(-l rt_F等)<BR>$ qsub -g GROUP -l rt_F=1<BR>  $ qsub -g GROUP -l rt_G.small=1 | 対応完了 |
| 2019/04/10 | Job | ジョブスケジューラのアップデート(8.5.4 -> 8.6.3)に伴い、以下のジョブ投入オプションは引数が必須になりました。BEEOND使用する場合は、-l USE_BEEONDオプションに"1"を省略せず指定してください。<BR>BEEOND 実行 (-l USE_BEEOND)<BR>$ qsub -g GROUP -l rt_F=2 -l USE_BEEOND=1 | 対応完了 |
| 2019/04/05 | Job | 通常計算ノードで rt_C.small/rt_G.small はそれぞれ最大で4ジョブまで実行されますが、ジョブスケジューラの不具合により、それぞれ最大2ジョブまでしか実行できない事象が発生しています。<br>Reservedサービスでも同様の事象が発生しており、rt_C.small/rt_G.small を使用の場合はご注意ください。<BR>$ qsub -ar ARID -l rt_G.small=1 -g GROUP run.sh (x 3回) <BR>$ qstat<BR>job-ID     prior   name       user         state<BR>--------<BR>    478583 0.25586 sample.sh  username   r<BR>    478584 0.25586 sample.sh  username   r<BR>    478586 0.25586 sample.sh  username   qw | 2019/10/04<br>対応完了 |
